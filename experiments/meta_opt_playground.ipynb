{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchviz import make_dot\n",
    "from torch.nn.utils import parameters_to_vector, vector_to_parameters\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "    \n",
    "class MetaModel(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super(MetaModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(d, 128)\n",
    "        self.fc2 = nn.Linear(128, d)\n",
    "    \n",
    "    def forward(self, theta_flat):\n",
    "        x = torch.relu(self.fc1(theta_flat))\n",
    "        return self.fc2(x)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train Loss 0.692639172077179\n",
      "\n",
      "Epoch 1, Train Loss 0.20576265454292297\n",
      "\n",
      "Epoch 2, Train Loss 0.9491184949874878\n",
      "\n",
      "Epoch 3, Train Loss 0.03838125243782997\n",
      "\n",
      "Epoch 4, Train Loss 0.12317118793725967\n",
      "\n",
      "Epoch 5, Train Loss 0.12265665829181671\n",
      "\n",
      "Epoch 6, Train Loss 0.028017327189445496\n",
      "\n",
      "Epoch 7, Train Loss 0.15350347757339478\n",
      "\n",
      "Epoch 8, Train Loss 0.01366340834647417\n",
      "\n",
      "Epoch 9, Train Loss 0.06852729618549347\n",
      "\n",
      "Epoch 10, Train Loss 0.05370870232582092\n",
      "\n",
      "Epoch 11, Train Loss 0.008035967126488686\n",
      "\n",
      "Epoch 12, Train Loss 0.060914501547813416\n",
      "\n",
      "Epoch 13, Train Loss 0.019319841638207436\n",
      "\n",
      "Epoch 14, Train Loss 0.00864302460104227\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_dim = 1\n",
    "hidden_dim = 20\n",
    "output_dim = 1\n",
    "d = sum(p.numel() for p in BaseModel(input_dim, hidden_dim, output_dim).parameters()) +1\n",
    "\n",
    "theta_f = BaseModel(input_dim, hidden_dim, output_dim)\n",
    "meta_model = MetaModel(d)\n",
    "optimizer = optim.Adam(meta_model.parameters(), lr=1e-2)\n",
    "\n",
    "n=1000\n",
    "X = torch.rand(n, input_dim)*4 -2\n",
    "Y = torch.tanh(X)\n",
    "# shuffle\n",
    "perm = torch.randperm(n)\n",
    "X = X[perm]\n",
    "Y = Y[perm]\n",
    "# random split\n",
    "X_train, X_test = X[:int(n*0.8)], X[int(n*0.8):]\n",
    "Y_train, Y_test = Y[:int(n*0.8)], Y[int(n*0.8):]\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for epoch in range(15):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # what if we reinit on each iteration? ie can meta model predict final weights from scratch\n",
    "    # theta_f = BaseModel(input_dim, hidden_dim, output_dim)  \n",
    "    \n",
    "    theta_flat = torch.cat([p.flatten() for p in theta_f.parameters()]).requires_grad_(True)\n",
    "    theta_flat = torch.cat([theta_flat, torch.tensor([epoch], dtype=torch.float32)]).requires_grad_(True)\n",
    "    \n",
    "    theta_flat_prime = meta_model(theta_flat)\n",
    "    \n",
    "    theta_f_prime = BaseModel(input_dim, hidden_dim, output_dim)\n",
    "    \n",
    "    params_dict = {}\n",
    "    start_idx = 0\n",
    "    for name, param in theta_f_prime.named_parameters():\n",
    "        param_length = param.numel()\n",
    "        params_dict[name] = theta_flat_prime[start_idx:start_idx + param_length].view_as(param)\n",
    "        start_idx += param_length\n",
    "    \n",
    "    def modified_forward(x):\n",
    "        # directly pass the weights into the forward pass. keeps the computation graph intact\n",
    "        x = F.linear(x, \n",
    "                    weight=params_dict['fc1.weight'],\n",
    "                    bias=params_dict['fc1.bias'])\n",
    "        x = torch.relu(x)\n",
    "        x = F.linear(x,\n",
    "                    weight=params_dict['fc2.weight'],\n",
    "                    bias=params_dict['fc2.bias'])\n",
    "        return x\n",
    "    \n",
    "    outputs = modified_forward(X_train)\n",
    "    loss = criterion(outputs, Y_train)\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    print(f'Epoch {epoch}, Train Loss {loss.item()}\\n')\n",
    "    \n",
    "    if epoch == 0:\n",
    "        make_dot(loss, params=dict(list(meta_model.named_parameters()))).render('comp_graph', format='png')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss 0.0432543121278286\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "theta_flat = torch.cat([p.flatten() for p in theta_f.parameters()]).requires_grad_(True)\n",
    "theta_flat = torch.cat([theta_flat, torch.tensor([epoch], dtype=torch.float32)]).requires_grad_(True)\n",
    "\n",
    "theta_flat_prime = meta_model(theta_flat)\n",
    "\n",
    "theta_f_prime = BaseModel(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "params_dict = {}\n",
    "start_idx = 0\n",
    "\n",
    "for name, param in theta_f_prime.named_parameters():\n",
    "    param_length = param.numel()\n",
    "    params_dict[name] = theta_flat_prime[start_idx:start_idx + param_length].view_as(param)\n",
    "    start_idx += param_length\n",
    "\n",
    "def modified_forward(x):\n",
    "    # directly pass the weights into the forward pass. keeps the computation graph intact\n",
    "    x = F.linear(x, \n",
    "                weight=params_dict['fc1.weight'],\n",
    "                bias=params_dict['fc1.bias'])\n",
    "    x = torch.relu(x)\n",
    "    x = F.linear(x,\n",
    "                weight=params_dict['fc2.weight'],\n",
    "                bias=params_dict['fc2.bias'])\n",
    "    return x\n",
    "\n",
    "outputs = modified_forward(X_test)\n",
    "loss = criterion(outputs, Y_test)\n",
    "print(f'Test Loss {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 0.8670465350151062\n",
      "\n",
      "Epoch 1, Loss 0.851166844367981\n",
      "\n",
      "Epoch 2, Loss 0.8354771137237549\n",
      "\n",
      "Epoch 3, Loss 0.8199802041053772\n",
      "\n",
      "Epoch 4, Loss 0.8046783208847046\n",
      "\n",
      "Epoch 5, Loss 0.7895739078521729\n",
      "\n",
      "Epoch 6, Loss 0.7746680974960327\n",
      "\n",
      "Epoch 7, Loss 0.7599632143974304\n",
      "\n",
      "Epoch 8, Loss 0.7454613447189331\n",
      "\n",
      "Epoch 9, Loss 0.7311623096466064\n",
      "\n",
      "Epoch 10, Loss 0.7170668244361877\n",
      "\n",
      "Epoch 11, Loss 0.7031756639480591\n",
      "\n",
      "Epoch 12, Loss 0.6894916892051697\n",
      "\n",
      "Epoch 13, Loss 0.6760116219520569\n",
      "\n",
      "Epoch 14, Loss 0.6627349853515625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = BaseModel(input_dim, hidden_dim, output_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()\n",
    "for epoch in range(15):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X)\n",
    "    loss = criterion(outputs, Y)\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    print(f'Epoch {epoch}, Loss {loss.item()}\\n')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
