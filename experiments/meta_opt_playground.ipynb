{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchviz import make_dot\n",
    "from torch.nn.utils import parameters_to_vector, vector_to_parameters\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "\n",
    "\n",
    "        seed = torch.randint(0, 1000, (1,)).item()\n",
    "        init_weights(self.fc1, seed)\n",
    "        init_weights(self.fc2, seed)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "    \n",
    "class MetaModel(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super(MetaModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(d, 128)\n",
    "        self.fc2 = nn.Linear(128, d)\n",
    "    \n",
    "    def forward(self, theta_flat):\n",
    "        x = torch.relu(self.fc1(theta_flat))\n",
    "        return self.fc2(x)\n",
    "\n",
    "    \n",
    "def init_weights(module, seed=0):\n",
    "    torch.manual_seed(seed)\n",
    "    # init weights with xavier \n",
    "    if isinstance(module, nn.Linear) or isinstance(module, nn.Conv2d):\n",
    "        nn.init.xavier_uniform_(module.weight)\n",
    "        nn.init.zeros_(module.bias)\n",
    "    #print(f\"Init weights with seed {seed}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init weights with seed 961\n",
      "Init weights with seed 961\n",
      "Init weights with seed 772\n",
      "Init weights with seed 772\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_dim = 1\n",
    "hidden_dim = 20\n",
    "output_dim = 1\n",
    "d = sum(p.numel() for p in BaseModel(input_dim, hidden_dim, output_dim).parameters()) +1\n",
    "\n",
    "n=1000\n",
    "X = torch.rand(n, input_dim)*4 -2\n",
    "Y = torch.tanh(X)\n",
    "# shuffle\n",
    "perm = torch.randperm(n)\n",
    "X = X[perm]\n",
    "Y = Y[perm]\n",
    "# random split\n",
    "X_train, X_test = X[:int(n*0.8)], X[int(n*0.8):]\n",
    "Y_train, Y_test = Y[:int(n*0.8)], Y[int(n*0.8):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 model\n",
    "theta_f = BaseModel(input_dim, hidden_dim, output_dim)\n",
    "meta_model = MetaModel(d)\n",
    "optimizer = optim.Adam(meta_model.parameters(), lr=1e-2)\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for epoch in range(15):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # what if we reinit on each iteration? ie can meta model predict final weights from scratch\n",
    "    # theta_f = BaseModel(input_dim, hidden_dim, output_dim)  \n",
    "    \n",
    "    theta_flat = torch.cat([p.flatten() for p in theta_f.parameters()]).requires_grad_(True)\n",
    "    theta_flat = torch.cat([theta_flat, torch.tensor([epoch], dtype=torch.float32)]).requires_grad_(True)\n",
    "    \n",
    "    theta_flat_prime = meta_model(theta_flat)\n",
    "    \n",
    "    theta_f_prime = BaseModel(input_dim, hidden_dim, output_dim)\n",
    "    \n",
    "    params_dict = {}\n",
    "    start_idx = 0\n",
    "    for name, param in theta_f_prime.named_parameters():\n",
    "        param_length = param.numel()\n",
    "        params_dict[name] = theta_flat_prime[start_idx:start_idx + param_length].view_as(param)\n",
    "        start_idx += param_length\n",
    "    \n",
    "    def modified_forward(x):\n",
    "        # directly pass the weights into the forward pass. keeps the computation graph intact\n",
    "        x = F.linear(x, \n",
    "                    weight=params_dict['fc1.weight'],\n",
    "                    bias=params_dict['fc1.bias'])\n",
    "        x = torch.relu(x)\n",
    "        x = F.linear(x,\n",
    "                    weight=params_dict['fc2.weight'],\n",
    "                    bias=params_dict['fc2.bias'])\n",
    "        return x\n",
    "    \n",
    "    outputs = modified_forward(X_train)\n",
    "    loss = criterion(outputs, Y_train)\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    print(f'Epoch {epoch}, Train Loss {loss.item()}\\n')\n",
    "    \n",
    "    if epoch == 0:\n",
    "        make_dot(loss, params=dict(list(meta_model.named_parameters()))).render('comp_graph', format='png')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train Loss 0.5187199115753174\n",
      "Epoch 0, Train Loss 0.2825659513473511\n",
      "Epoch 0, Train Loss 0.021471483632922173\n",
      "Epoch 0, Train Loss 0.3502190113067627\n",
      "Epoch 0, Train Loss 0.021631114184856415\n",
      "Epoch 0, Train Loss 0.10376334190368652\n",
      "Epoch 0, Train Loss 0.1685345470905304\n",
      "Epoch 0, Train Loss 0.18142744898796082\n",
      "Epoch 0, Train Loss 0.15931108593940735\n",
      "Epoch 0, Train Loss 0.11640456318855286\n",
      "Epoch 0, Train Loss 0.06744590401649475\n",
      "Epoch 0, Train Loss 0.03233504295349121\n",
      "Epoch 0, Train Loss 0.02963540330529213\n",
      "Epoch 0, Train Loss 0.04857634752988815\n",
      "Epoch 0, Train Loss 0.05411198362708092\n",
      "Epoch 0, Train Loss 0.03694517910480499\n",
      "Epoch 0, Train Loss 0.019580623134970665\n",
      "Epoch 0, Train Loss 0.01593651995062828\n",
      "Epoch 0, Train Loss 0.021632686257362366\n",
      "Epoch 0, Train Loss 0.02664417028427124\n",
      "Epoch 0, Train Loss 0.026548776775598526\n",
      "Epoch 0, Train Loss 0.024729304015636444\n",
      "Epoch 0, Train Loss 0.022818565368652344\n",
      "Epoch 0, Train Loss 0.01745016500353813\n",
      "Epoch 0, Train Loss 0.008907224982976913\n",
      "Epoch 0, Train Loss 0.004846625495702028\n",
      "Epoch 0, Train Loss 0.009543819352984428\n",
      "Epoch 0, Train Loss 0.015554346144199371\n",
      "Epoch 0, Train Loss 0.015461023896932602\n",
      "Epoch 0, Train Loss 0.01079585775732994\n",
      "Epoch 0, Train Loss 0.005823287181556225\n",
      "Epoch 0, Train Loss 0.004188785329461098\n",
      "Epoch 0, Train Loss 0.006235671229660511\n",
      "Epoch 0, Train Loss 0.008349900133907795\n",
      "Epoch 0, Train Loss 0.008476322516798973\n",
      "Epoch 0, Train Loss 0.007995949126780033\n",
      "Epoch 0, Train Loss 0.007188672199845314\n",
      "Epoch 0, Train Loss 0.005320579279214144\n",
      "Epoch 0, Train Loss 0.003478503320366144\n",
      "Epoch 0, Train Loss 0.0033143702894449234\n",
      "Epoch 0, Train Loss 0.004387400578707457\n",
      "Epoch 0, Train Loss 0.0053777312859892845\n",
      "Epoch 0, Train Loss 0.005360377952456474\n",
      "Epoch 0, Train Loss 0.0040874481201171875\n",
      "Epoch 0, Train Loss 0.002871759468689561\n",
      "Epoch 0, Train Loss 0.0028942914213985205\n",
      "Epoch 0, Train Loss 0.003315932350233197\n",
      "Epoch 0, Train Loss 0.00338654569350183\n",
      "Epoch 0, Train Loss 0.003375385422259569\n",
      "Epoch 0, Train Loss 0.003160621505230665\n",
      "Epoch 0, Train Loss 0.0026958133094012737\n",
      "Epoch 0, Train Loss 0.0023307749070227146\n",
      "Epoch 0, Train Loss 0.0021880795247852802\n",
      "Epoch 0, Train Loss 0.0023073467891663313\n",
      "Epoch 0, Train Loss 0.002562224864959717\n",
      "Epoch 0, Train Loss 0.0024048832710832357\n",
      "Epoch 0, Train Loss 0.0019701963756233454\n",
      "Epoch 0, Train Loss 0.00180145725607872\n",
      "Epoch 0, Train Loss 0.0018291305750608444\n",
      "Epoch 0, Train Loss 0.0019114731112495065\n",
      "Epoch 0, Train Loss 0.0019086562097072601\n",
      "Epoch 0, Train Loss 0.0017691486282274127\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'fc1.weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 45\u001b[0m\n\u001b[1;32m     39\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlinear(x,\n\u001b[1;32m     40\u001b[0m                 weight\u001b[38;5;241m=\u001b[39mparams_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfc2.weight\u001b[39m\u001b[38;5;124m'\u001b[39m][idx],\n\u001b[1;32m     41\u001b[0m                 bias\u001b[38;5;241m=\u001b[39mparams_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfc2.bias\u001b[39m\u001b[38;5;124m'\u001b[39m][idx])\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m---> 45\u001b[0m outputs \u001b[38;5;241m=\u001b[39m [modified_forward(X_train, model, idx) \u001b[38;5;28;01mfor\u001b[39;00m idx, model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch_prime)]\n\u001b[1;32m     46\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([criterion(output, Y_train) \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs])\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     47\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Cell \u001b[0;32mIn[24], line 45\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     39\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlinear(x,\n\u001b[1;32m     40\u001b[0m                 weight\u001b[38;5;241m=\u001b[39mparams_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfc2.weight\u001b[39m\u001b[38;5;124m'\u001b[39m][idx],\n\u001b[1;32m     41\u001b[0m                 bias\u001b[38;5;241m=\u001b[39mparams_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfc2.bias\u001b[39m\u001b[38;5;124m'\u001b[39m][idx])\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m---> 45\u001b[0m outputs \u001b[38;5;241m=\u001b[39m [\u001b[43mmodified_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx, model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch_prime)]\n\u001b[1;32m     46\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([criterion(output, Y_train) \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs])\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     47\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Cell \u001b[0;32mIn[24], line 36\u001b[0m, in \u001b[0;36mmodified_forward\u001b[0;34m(x, model, idx)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmodified_forward\u001b[39m(x, model, idx):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# directly pass the weights\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlinear(x, \n\u001b[0;32m---> 36\u001b[0m                 weight\u001b[38;5;241m=\u001b[39m\u001b[43mparams_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfc1.weight\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[idx],\n\u001b[1;32m     37\u001b[0m                 bias\u001b[38;5;241m=\u001b[39mparams_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfc1.bias\u001b[39m\u001b[38;5;124m'\u001b[39m][idx])\n\u001b[1;32m     38\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m     39\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlinear(x,\n\u001b[1;32m     40\u001b[0m                 weight\u001b[38;5;241m=\u001b[39mparams_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfc2.weight\u001b[39m\u001b[38;5;124m'\u001b[39m][idx],\n\u001b[1;32m     41\u001b[0m                 bias\u001b[38;5;241m=\u001b[39mparams_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfc2.bias\u001b[39m\u001b[38;5;124m'\u001b[39m][idx])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'fc1.weight'"
     ]
    }
   ],
   "source": [
    "#k models\n",
    "k = 500\n",
    "batch_size = 8\n",
    "optimizees = [BaseModel(input_dim, hidden_dim, output_dim) for _ in range(k)]\n",
    "meta_model = MetaModel(d).to('cuda')\n",
    "optimizer = optim.Adam(meta_model.parameters(), lr=1e-2)\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.MSELoss()\n",
    "X_train = X_train.to('cuda')\n",
    "Y_train = Y_train.to('cuda')\n",
    "\n",
    "for epoch in range(100):\n",
    "    for i in range(0, k, batch_size):\n",
    "        batch = optimizees[i:i+batch_size]\n",
    "        batch_flattened = [torch.cat([torch.cat([p.flatten() for p in model.parameters()]), torch.tensor([epoch], dtype=torch.float32)]) for model in batch]\n",
    "        batch_flattened = torch.stack(batch_flattened).to('cuda')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        theta_flat_prime = meta_model(batch_flattened)\n",
    "        \n",
    "        batch_prime = [BaseModel(input_dim, hidden_dim, output_dim) for _ in range(batch_size)]\n",
    "        params_dict = {}\n",
    "        start_idx = 0\n",
    "        for name, param in batch_prime[0].named_parameters():\n",
    "            param_length = param.numel()\n",
    "            try:\n",
    "                params_dict[name] = theta_flat_prime[:, start_idx:start_idx + param_length].view(batch_size, *param.shape)\n",
    "                # fails when parm shape [20,1]\n",
    "            except:\n",
    "                x=1\n",
    "            start_idx += param_length\n",
    "\n",
    "        def modified_forward(x, model, idx):\n",
    "            # directly pass the weights\n",
    "            x = F.linear(x, \n",
    "                        weight=params_dict['fc1.weight'][idx],\n",
    "                        bias=params_dict['fc1.bias'][idx])\n",
    "            x = torch.relu(x)\n",
    "            x = F.linear(x,\n",
    "                        weight=params_dict['fc2.weight'][idx],\n",
    "                        bias=params_dict['fc2.bias'][idx])\n",
    "            return x\n",
    "        \n",
    "        \n",
    "        outputs = [modified_forward(X_train, model, idx) for idx, model in enumerate(batch_prime)]\n",
    "        loss = torch.stack([criterion(output, Y_train) for output in outputs]).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f'Epoch {epoch}, Train Loss {loss.item()}')\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 0.8670465350151062\n",
      "\n",
      "Epoch 1, Loss 0.851166844367981\n",
      "\n",
      "Epoch 2, Loss 0.8354771137237549\n",
      "\n",
      "Epoch 3, Loss 0.8199802041053772\n",
      "\n",
      "Epoch 4, Loss 0.8046783208847046\n",
      "\n",
      "Epoch 5, Loss 0.7895739078521729\n",
      "\n",
      "Epoch 6, Loss 0.7746680974960327\n",
      "\n",
      "Epoch 7, Loss 0.7599632143974304\n",
      "\n",
      "Epoch 8, Loss 0.7454613447189331\n",
      "\n",
      "Epoch 9, Loss 0.7311623096466064\n",
      "\n",
      "Epoch 10, Loss 0.7170668244361877\n",
      "\n",
      "Epoch 11, Loss 0.7031756639480591\n",
      "\n",
      "Epoch 12, Loss 0.6894916892051697\n",
      "\n",
      "Epoch 13, Loss 0.6760116219520569\n",
      "\n",
      "Epoch 14, Loss 0.6627349853515625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = BaseModel(input_dim, hidden_dim, output_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()\n",
    "for epoch in range(15):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X)\n",
    "    loss = criterion(outputs, Y)\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    print(f'Epoch {epoch}, Loss {loss.item()}\\n')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
